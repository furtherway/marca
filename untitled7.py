# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YKwEpwTJQLZO1qOfdYMWZKhpUQaIYWcK

# 1. Generaci√≥n de Base a Entrenar Modelo (XBoost de Confusi√≥n)
"""

# 1. Instalar dependencias
# !pip install python-Levenshtein pandas jellyfish scikit-learn

# 2. Imports
import random
import pandas as pd
import Levenshtein
import jellyfish
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

# 3. Configuraci√≥n
BASE_WORDS = [w.lower() for w in [
    'Alpha','Beta','Gamma','Delta','Omega','Vertex','Nexus','Pioneer',
    'Quantum','Nova','Apex','Summit','Fusion','Spectrum','Vector',
    'Prime','Edge','Core','Pulse','Echo','Zenith','Horizon','Vista'
]]
SUFFIXES = [s.lower() for s in [
    'Tech','Tek','Systems','Solutions','Dynamics','Global','Works',
    'Labs','Corp','Soft'
]]
THRESHOLD = 0.4  # umbral para Levenshtein

def rhyme(a: str, b: str) -> bool:
    """Comprueba si riman: √∫ltimos 4 caracteres iguales."""
    return a[-4:] == b[-4:]

def generate_brand_pairs(n: int = 500) -> pd.DataFrame:
    records = []
    for _ in range(n):
        b1 = f"{random.choice(BASE_WORDS)} {random.choice(SUFFIXES)}"
        b2 = f"{random.choice(BASE_WORDS)} {random.choice(SUFFIXES)}"
        # 1) Levenshtein
        dist = Levenshtein.distance(b1, b2)
        norm_dist = dist / max(len(b1), len(b2), 1)
        lev_conf = norm_dist < THRESHOLD
        # 2) Substring
        substr_conf = bool(set(b1.split()) & set(b2.split()))
        # 3) Fon√©tica (Metaphone)
        ph1, ph2 = jellyfish.metaphone(b1), jellyfish.metaphone(b2)
        phon_conf = (ph1 == ph2 and ph1 != "")
        # 4) Rima
        rhyme_conf = rhyme(b1.replace(" ", ""), b2.replace(" ", ""))
        # Etiqueta final
        label = int(any([lev_conf, substr_conf, phon_conf, rhyme_conf]))
        records.append({
            "brand_new": b1,
            "brand_existing": b2,
            "norm_dist": norm_dist,
            "substr_conf": int(substr_conf),
            "phonetic_conf": int(phon_conf),
            "rhyme_conf": int(rhyme_conf),
            "label": label
        })
    return pd.DataFrame.from_records(records)

# 4. Generar y guardar dataset
random.seed(42)
df = generate_brand_pairs(200)
df.to_csv('brands_pairs.csv', index=False)
print("‚úîÔ∏è Dataset creado: 'brands_pairs.csv'")

# 5. Entrenar el modelo
X = df[["norm_dist","substr_conf","phonetic_conf","rhyme_conf"]]
y = df["label"]
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
clf = RandomForestClassifier(random_state=42, n_estimators=100)
clf.fit(X_train, y_train)

# 6. Evaluaci√≥n
y_pred = clf.predict(X_test)
print("Classification Report:\n", classification_report(y_test, y_pred, digits=4))

"""# 2. Modelo de Predicci√≥n Xboost (Confusi√≥n)"""

# En Colab, instala dependencias si no lo has hecho:
# !pip install python-Levenshtein jellyfish xgboost scikit-learn pandas numpy ipywidgets --quiet

import pandas as pd
import numpy as np
import Levenshtein
import jellyfish
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import roc_auc_score, classification_report

# Para la interfaz de texto
import ipywidgets as widgets
from IPython.display import display, clear_output

# ----------------------------
# 1) Funciones de procesamiento
# ----------------------------
def extract_features(b1: str, b2: str) -> list:
    b1, b2 = b1.lower(), b2.lower()
    # 1) Distancia de Levenshtein normalizada
    lev_norm = Levenshtein.distance(b1, b2) / max(len(b1), len(b2), 1)
    # 2) Similitud Jaro-Winkler
    jaro_w = jellyfish.jaro_winkler_similarity(b1, b2)
    # 3) Longest Common Subsequence ratio
    lcs = Levenshtein.seqratio(b1, b2)
    # 4) Jaccard sobre tokens
    t1, t2 = set(b1.split()), set(b2.split())
    jac = len(t1 & t2) / max(len(t1 | t2), 1)
    # 5) Coincidencia posici√≥n a posici√≥n
    same_pos = sum(c1 == c2 for c1, c2 in zip(b1, b2)) / max(min(len(b1), len(b2)), 1)
    return [lev_norm, jaro_w, lcs, jac, same_pos]

def load_data(path_csv: str):
    df = pd.read_csv(path_csv)
    feats = df.apply(lambda r: extract_features(r['brand_new'], r['brand_existing']), axis=1)
    X = np.vstack(feats.values)
    y = df['label'].astype(int).values
    return X, y

# ----------------------------
# 2) Carga y entrenamiento
# ----------------------------
X, y = load_data('brands_pairs.csv')

# Partici√≥n
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Configurar XGBoost
model = XGBClassifier(
    objective='binary:logistic',
    eval_metric='auc',
    use_label_encoder=False,
    random_state=42
)
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.05, 0.1],
    'subsample': [0.8, 1.0],
    'colsample_bytree': [0.8, 1.0]
}

grid = GridSearchCV(
    model,
    param_grid,
    scoring='roc_auc',
    cv=3,
    n_jobs=-1,
    verbose=1
)
grid.fit(X_train, y_train)

best = grid.best_estimator_
print(f"‚ñ∂Ô∏è ROC AUC en test: {roc_auc_score(y_test, best.predict_proba(X_test)[:,1]):.3f}")
print("‚ñ∂Ô∏è Mejores hiperpar√°metros:", grid.best_params_)
print(classification_report(y_test, best.predict(X_test)))

# ----------------------------
# 3) Interfaz interactiva
# ----------------------------
def predict_confusion(b_new: str, b_exist: str) -> float:
    feats = np.array([extract_features(b_new, b_exist)])
    return best.predict_proba(feats)[0,1]

text_new = widgets.Text(
    placeholder='Escribe aqu√≠ la marca nueva',
    description='Marca nueva:',
    layout=widgets.Layout(width='60%')
)
text_exist = widgets.Text(
    placeholder='Escribe aqu√≠ la marca previa',
    description='Marca existente:',
    layout=widgets.Layout(width='60%')
)
button = widgets.Button(description='Calcular probabilidad', button_style='info')
output = widgets.Output()

def on_click(b):
    with output:
        clear_output()
        bn, be = text_new.value.strip(), text_exist.value.strip()
        if not bn or not be:
            print("üî¥ Por favor, ingresa ambos nombres de marca.")
            return
        p = predict_confusion(bn, be)
        print(f"üìä Probabilidad de confusi√≥n entre ‚Äú{bn}‚Äù y ‚Äú{be}‚Äù: {p:.3f}")

button.on_click(on_click)
display(text_new, text_exist, button, output)
